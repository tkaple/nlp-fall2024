{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<<OPEN_API_PERSONAL_KEY_HERE>>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2618d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd3b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PERSIST_DIRECTORY = \"./chroma_db\"\n",
    "EMBEDDINGS_MODEL = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "occupation = \"politician\"\n",
    "target_collection_name_2 = occupation + \"_template_files\" \n",
    "embeddings_2 = SentenceTransformerEmbeddings(model_name=EMBEDDINGS_MODEL)\n",
    "print(\"Target Collection Is: \" + target_collection_name_2)\n",
    "chroma_db_from_disk_2 = Chroma(persist_directory=CHROMA_PERSIST_DIRECTORY,                             \n",
    "                            collection_name=target_collection_name_2,\n",
    "                            embedding_function=embeddings_2)\n",
    "results_templates = chroma_db_from_disk_2._collection.get(include=[\"documents\", \"metadatas\", \"embeddings\"])\n",
    "documents_templates = [\n",
    "    Document(page_content=doc, metadata=meta)\n",
    "    for doc, meta in zip(results_templates[\"documents\"], results_templates[\"metadatas\"])\n",
    "]\n",
    "template_sentences = results_templates[\"documents\"][2] ## Can use any here\n",
    "template_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf7018",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(template_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62409081",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation = \"politician\"\n",
    "CHROMA_CHUNK_SIZE = 1000\n",
    "CHROMA_PERSIST_DIRECTORY = \"./chroma_db\"\n",
    "CHROMA_COLLECTION_NAME = occupation + \"_generated_articles\"\n",
    "EMBEDDINGS_MODEL = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "start_time = time.time()\n",
    "target_collection_name = occupation + \"_generated_articles\"\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=EMBEDDINGS_MODEL)\n",
    "print(\"Target Collection Is: \" + target_collection_name)\n",
    "chroma_db_from_disk = Chroma(persist_directory=CHROMA_PERSIST_DIRECTORY,                             \n",
    "                            collection_name=target_collection_name,\n",
    "                            embedding_function=embeddings)\n",
    "results = chroma_db_from_disk._collection.get(include=[\"documents\", \"metadatas\", \"embeddings\"])\n",
    "documents = [\n",
    "    Document(page_content=doc, metadata=meta)\n",
    "    for doc, meta in zip(results[\"documents\"], results[\"metadatas\"])\n",
    "]\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(\"Number of Documents: \"+  str(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ebc76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "from ragas import SingleTurnSample \n",
    "from ragas.metrics import Faithfulness, ResponseRelevancy\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4\"))\n",
    "evaluator_embeddings = OpenAIEmbeddings()\n",
    "count = 0 \n",
    "with open(\"Ragas_Evaluation_V2.json\",\"w\") as f:\n",
    "    for doc in documents:\n",
    "        count += 1\n",
    "        #rint(doc)\n",
    "        page_content = doc.page_content\n",
    "        my_metadata = doc.metadata\n",
    "        #rint(page_content)\n",
    "        first_name = my_metadata[\"first_name\"]\n",
    "        last_name = my_metadata[\"last_name\"]\n",
    "        entity_name = first_name + \" \" +last_name\n",
    "        response_marker = \"### Response:\"\n",
    "        ########## Parse Generated Artcicle ###########\n",
    "        try:\n",
    "            if response_marker in page_content:\n",
    "                response_start = page_content.index(response_marker) + len(response_marker)\n",
    "                generated_article = page_content[response_start:].strip() \n",
    "                #rint(\"Extracted Response:\")\n",
    "                #rint(generated_article)\n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "            continue\n",
    "        ########## Get JSON from Chroma  ##########\n",
    "        target_collection_name = occupation + \"_json_files\" \n",
    "        embeddings = SentenceTransformerEmbeddings(model_name=EMBEDDINGS_MODEL)\n",
    "        #rint(\"Target Collection Is: \" + target_collection_name)\n",
    "        chroma_db_from_disk = Chroma(persist_directory=CHROMA_PERSIST_DIRECTORY,                             \n",
    "                                    collection_name=target_collection_name,\n",
    "                                    embedding_function=embeddings)\n",
    "        results = chroma_db_from_disk.get(\n",
    "            where={\n",
    "                \"$and\": [\n",
    "                    {\"first_name\": first_name},\n",
    "                    {\"last_name\": last_name}\n",
    "                ]\n",
    "            },\n",
    "            include=[\"documents\", \"metadatas\"])\n",
    "        documents = [\n",
    "            Document(page_content=doc, metadata=meta)\n",
    "            for doc, meta in zip(results[\"documents\"], results[\"metadatas\"])\n",
    "        ]\n",
    "        document = documents[0]\n",
    "        content = ast.literal_eval(document.page_content)[0]\n",
    "        response_start = content.index(\"### Response:\")\n",
    "        json_start = content.index(\"{\", response_start)\n",
    "        json_end = content.rindex(\"}\")\n",
    "        json_string = content[json_start:json_end+1]\n",
    "        try:\n",
    "            parsed_dict = ast.literal_eval(json_string)\n",
    "            json_data = json.dumps(parsed_dict, ensure_ascii=False, indent=2)\n",
    "            #print(json_data)\n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "            continue\n",
    "        ########### Faithfulness ##############\n",
    "        prompt = f\"Generate an Article in Hindi Language for {entity_name} using the details given in the json string below. Strictly use the given template sentences as a reference. Do not any other extra English text after the article.\"\n",
    "        sample = SingleTurnSample(\n",
    "        user_input= prompt, \n",
    "        response=generated_article,\n",
    "        retrieved_contexts=[\n",
    "            #template_sentences,\n",
    "            json_data\n",
    "                ]\n",
    "            )\n",
    "        scorer = Faithfulness()\n",
    "        scorer.llm = evaluator_llm\n",
    "        faithfulness_score = await scorer.single_turn_ascore(sample)\n",
    "        print(\"FaithFulness Score Is: \" + str(faithfulness_score))\n",
    "        ########### Relevancy ###################\n",
    "        rel_scorer = ResponseRelevancy()\n",
    "        rel_scorer.llm = evaluator_llm\n",
    "        rel_scorer.embeddings = evaluator_embeddings\n",
    "        relevancy_score = await rel_scorer.single_turn_ascore(sample)\n",
    "        print(\"Relevancy score is: \" + str(relevancy_score))\n",
    "        op = { \"First Name\": first_name, \"Last Name\": last_name, \"Faithfullness Score\": faithfulness_score, \n",
    "              \"Relevancy\": relevancy_score}\n",
    "        json.dump(op, f, indent=4)\n",
    "        print(\"count\" + str(count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv]",
   "language": "python",
   "name": "conda-env-.conda-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
